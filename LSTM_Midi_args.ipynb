{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Midi-args",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSNk-aQwCZxu",
        "colab_type": "code",
        "outputId": "8e273cb0-2753-4420-ab1b-4a7f4120d1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! git clone https://github.com/brannondorsey/midi-rnn.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'midi-rnn'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Total 248 (delta 0), reused 0 (delta 0), pack-reused 248\u001b[K\n",
            "Receiving objects: 100% (248/248), 413.79 KiB | 578.00 KiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC19aHZeIN1C",
        "colab_type": "code",
        "outputId": "1dafbf30-0076-4af3-c123-be147ba47648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%cd midi-rnn \n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'midi-rnn'\n",
            "/content/midi-rnn\n",
            "data\t     GPL.txt  __pycache__  requirements.txt  train.py\n",
            "experiments  LICENSE  README.md    sample.py\t     utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG8gW5AjPfTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1VRdYQ_wpvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob, random\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from multiprocessing import Pool as ThreadPool\n",
        "\n",
        "def log(message, verbose):\n",
        "\tif verbose:\n",
        "\t\tprint('[*] {}'.format(message))\n",
        "\n",
        "def parse_midi(path):\n",
        "    midi = None\n",
        "    try:\n",
        "        midi = pretty_midi.PrettyMIDI(path)\n",
        "        midi.remove_invalid_notes()\n",
        "    except Exception as e:\n",
        "        raise Exception((\"%s\\nerror readying midi file %s\" % (e, path)))\n",
        "    return midi\n",
        "\n",
        "def get_percent_monophonic(pm_instrument_roll):\n",
        "    mask = pm_instrument_roll.T > 0\n",
        "    notes = np.sum(mask, axis=1)\n",
        "    n = np.count_nonzero(notes)\n",
        "    single = np.count_nonzero(notes == 1)\n",
        "    if single > 0:\n",
        "        return float(single) / float(n)\n",
        "    elif single == 0 and n > 0:\n",
        "        return 0.0\n",
        "    else: # no notes of any kind\n",
        "        return 0.0\n",
        "    \n",
        "def filter_monophonic(pm_instruments, percent_monophonic=0.99):\n",
        "    return [i for i in pm_instruments if \\\n",
        "            get_percent_monophonic(i.get_piano_roll()) >= percent_monophonic]\n",
        "\n",
        "\n",
        "# if the experiment dir doesn't exist create it and its subfolders\n",
        "def create_experiment_dir(experiment_dir, verbose=False):\n",
        "    \n",
        "    # if the experiment directory was specified and already exists\n",
        "    if experiment_dir != 'experiments/default' and \\\n",
        "       os.path.exists(experiment_dir):\n",
        "    \t# raise an error\n",
        "    \traise Exception('Error: Invalid --experiemnt_dir, {} already exists' \\\n",
        "    \t\t            .format(experiment_dir))\n",
        "\n",
        "    # if the experiment directory was not specified, create a new numeric folder\n",
        "    if experiment_dir == 'experiments/default':\n",
        "    \t\n",
        "    \texperiments = os.listdir('experiments')\n",
        "    \texperiments = [dir_ for dir_ in experiments \\\n",
        "    \t               if os.path.isdir(os.path.join('experiments', dir_))]\n",
        "    \t\n",
        "    \tmost_recent_exp = 0\n",
        "    \tfor dir_ in experiments:\n",
        "    \t\ttry:\n",
        "    \t\t\tmost_recent_exp = max(int(dir_), most_recent_exp)\n",
        "    \t\texcept ValueError as e:\n",
        "    \t\t\t# ignrore non-numeric folders in experiments/\n",
        "    \t\t\tpass\n",
        "\n",
        "    \texperiment_dir = os.path.join('experiments', \n",
        "    \t\t                          str(most_recent_exp + 1).rjust(2, '0'))\n",
        "\n",
        "    os.mkdir(experiment_dir)\n",
        "    log('Created experiment directory {}'.format(experiment_dir), verbose)\n",
        "    os.mkdir(os.path.join(experiment_dir, 'checkpoints'))\n",
        "    log('Created checkpoint directory {}'.format(os.path.join(experiment_dir, 'checkpoints')),\n",
        "    \tverbose)\n",
        "    os.mkdir(os.path.join(experiment_dir, 'tensorboard-logs'))\n",
        "    log('Created log directory {}'.format(os.path.join(experiment_dir, 'tensorboard-logs')), \n",
        "    \tverbose)\n",
        "\n",
        "    return experiment_dir\n",
        "\n",
        "# load data with a lazzy loader\n",
        "def get_data_generator(midi_paths, \n",
        "                       window_size=20, \n",
        "                       batch_size=32,\n",
        "                       num_threads=8,\n",
        "                       max_files_in_ram=170):\n",
        "\n",
        "    if num_threads > 1:\n",
        "    \t# load midi data\n",
        "    \tpool = ThreadPool(num_threads)\n",
        "\n",
        "    load_index = 0\n",
        "\n",
        "    while True:\n",
        "        load_files = midi_paths[load_index:load_index + max_files_in_ram]\n",
        "        # print('length of load files: {}'.format(len(load_files)))\n",
        "        load_index = (load_index + max_files_in_ram) % len(midi_paths)\n",
        "\n",
        "        # print('loading large batch: {}'.format(max_files_in_ram))\n",
        "        # print('Parsing midi files...')\n",
        "        # start_time = time.time()\n",
        "        if num_threads > 1:\n",
        "       \t\tparsed = pool.map(parse_midi, load_files)\n",
        "       \telse:\n",
        "       \t\tparsed = map(parse_midi, load_files)\n",
        "        # print('Finished in {:.2f} seconds'.format(time.time() - start_time))\n",
        "        # print('parsed, now extracting data')\n",
        "        data = _windows_from_monophonic_instruments(parsed, window_size)\n",
        "        batch_index = 0\n",
        "        while batch_index + batch_size < len(data[0]):\n",
        "            # print('getting data...')\n",
        "            # print('yielding small batch: {}'.format(batch_size))\n",
        "            \n",
        "            res = (data[0][batch_index: batch_index + batch_size], \n",
        "                   data[1][batch_index: batch_index + batch_size])\n",
        "            yield res\n",
        "            batch_index = batch_index + batch_size\n",
        "        \n",
        "        # probably unneeded but why not\n",
        "        del parsed # free the mem\n",
        "        del data # free the mem\n",
        "\n",
        "def save_model(model, model_dir):\n",
        "    with open(os.path.join(model_dir, 'model.json'), 'w') as f:\n",
        "        f.write(model.to_json())\n",
        "\n",
        "def load_model_from_checkpoint(model_dir):\n",
        "\n",
        "    '''Loads the best performing model from checkpoint_dir'''\n",
        "    with open(os.path.join(model_dir, 'model.json'), 'r') as f:\n",
        "        model = model_from_json(f.read())\n",
        "\n",
        "    epoch = 0\n",
        "    newest_checkpoint = max(glob.iglob(model_dir + \n",
        "    \t                    '/checkpoints/*.hdf5'), \n",
        "                            key=os.path.getctime)\n",
        "    print(newest_checkpoint)\n",
        "    if newest_checkpoint: \n",
        "      #  epoch = int(newest_checkpoint[-22:-19])\n",
        "       epoch = 1\n",
        "       model.load_weights(newest_checkpoint)\n",
        "\n",
        "    return model, epoch\n",
        "\n",
        "def generate(model, seeds, window_size, length, num_to_gen, instrument_name):\n",
        "    \n",
        "    # generate a pretty midi file from a model using a seed\n",
        "    def _gen(model, seed, window_size, length):\n",
        "        \n",
        "        generated = []\n",
        "        # ring buffer\n",
        "        buf = np.copy(seed).tolist()\n",
        "        while len(generated) < length:\n",
        "            arr = np.expand_dims(np.asarray(buf), 0)\n",
        "            pred = model.predict(arr)\n",
        "            \n",
        "            # argmax sampling (NOT RECOMMENDED), or...\n",
        "            # index = np.argmax(pred)\n",
        "            \n",
        "            # prob distrobuition sampling\n",
        "            index = np.random.choice(range(0, seed.shape[1]), p=pred[0])\n",
        "            pred = np.zeros(seed.shape[1])\n",
        "\n",
        "            pred[index] = 1\n",
        "            generated.append(pred)\n",
        "            buf.pop(0)\n",
        "            buf.append(pred)\n",
        "\n",
        "        return generated\n",
        "\n",
        "    midis = []\n",
        "    for i in range(0, num_to_gen):\n",
        "        seed = seeds[random.randint(0, len(seeds) - 1)]\n",
        "        gen = _gen(model, seed, window_size, length)\n",
        "        midis.append(_network_output_to_midi(gen, instrument_name))\n",
        "    return midis\n",
        "\n",
        "# create a pretty midi file with a single instrument using the one-hot encoding\n",
        "# output of keras model.predict.\n",
        "def _network_output_to_midi(windows, \n",
        "                           instrument_name='Acoustic Grand Piano', \n",
        "                           allow_represses=False):\n",
        "\n",
        "    # Create a PrettyMIDI object\n",
        "    midi = pretty_midi.PrettyMIDI()\n",
        "    # Create an Instrument instance for a cello instrument\n",
        "    instrument_program = pretty_midi.instrument_name_to_program(instrument_name)\n",
        "    instrument = pretty_midi.Instrument(program=instrument_program)\n",
        "    \n",
        "    cur_note = None # an invalid note to start with\n",
        "    cur_note_start = None\n",
        "    clock = 0\n",
        "\n",
        "    # Iterate over note names, which will be converted to note number later\n",
        "    for step in windows:\n",
        "\n",
        "        note_num = np.argmax(step) - 1\n",
        "        \n",
        "        # a note has changed\n",
        "        if allow_represses or note_num != cur_note:\n",
        "            \n",
        "            # if a note has been played before and it wasn't a rest\n",
        "            if cur_note is not None and cur_note >= 0:            \n",
        "                # add the last note, now that we have its end time\n",
        "                note = pretty_midi.Note(velocity=127, \n",
        "                                        pitch=int(cur_note), \n",
        "                                        start=cur_note_start, \n",
        "                                        end=clock)\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "            # update the current note\n",
        "            cur_note = note_num\n",
        "            cur_note_start = clock\n",
        "\n",
        "        # update the clock\n",
        "        clock = clock + 1.0 / 4\n",
        "\n",
        "    # Add the cello instrument to the PrettyMIDI object\n",
        "    midi.instruments.append(instrument)\n",
        "    return midi\n",
        "\n",
        "# returns X, y data windows from all monophonic instrument\n",
        "# tracks in a pretty midi file\n",
        "def _windows_from_monophonic_instruments(midi, window_size):\n",
        "    X, y = [], []\n",
        "    for m in midi:\n",
        "        if m is not None:\n",
        "            melody_instruments = filter_monophonic(m.instruments, 1.0)\n",
        "            for instrument in melody_instruments:\n",
        "                if len(instrument.notes) > window_size:\n",
        "                    windows = _encode_sliding_windows(instrument, window_size)\n",
        "                    for w in windows:\n",
        "                        X.append(w[0])\n",
        "                        y.append(w[1])\n",
        "    return (np.asarray(X), np.asarray(y))\n",
        "\n",
        "# one-hot encode a sliding window of notes from a pretty midi instrument.\n",
        "# This approach uses the piano roll method, where each step in the sliding\n",
        "# window represents a constant unit of time (fs=4, or 1 sec / 4 = 250ms).\n",
        "# This allows us to encode rests.\n",
        "# expects pm_instrument to be monophonic.\n",
        "def _encode_sliding_windows(pm_instrument, window_size):\n",
        "    \n",
        "    roll = np.copy(pm_instrument.get_piano_roll(fs=4).T)\n",
        "\n",
        "    # trim beginning silence\n",
        "    summed = np.sum(roll, axis=1)\n",
        "    mask = (summed > 0).astype(float)\n",
        "    roll = roll[np.argmax(mask):]\n",
        "    \n",
        "    # transform note velocities into 1s\n",
        "    roll = (roll > 0).astype(float)\n",
        "    \n",
        "    # calculate the percentage of the events that are rests\n",
        "    # s = np.sum(roll, axis=1)\n",
        "    # num_silence = len(np.where(s == 0)[0])\n",
        "    # print('{}/{} {:.2f} events are rests'.format(num_silence, len(roll), float(num_silence)/float(len(roll))))\n",
        "\n",
        "    # append a feature: 1 to rests and 0 to notes\n",
        "    rests = np.sum(roll, axis=1)\n",
        "    rests = (rests != 1).astype(float)\n",
        "    roll = np.insert(roll, 0, rests, axis=1)\n",
        "    \n",
        "    windows = []\n",
        "    for i in range(0, roll.shape[0] - window_size - 1):\n",
        "        windows.append((roll[i:i + window_size], roll[i + window_size + 1]))\n",
        "    return windows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzUJAimxP-zP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "137805ad-a108-4c10-d87c-b4e97ffd7133"
      },
      "source": [
        "import os, argparse, time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
        "\n",
        "OUTPUT_SIZE = 129 # 0-127 notes + 1 for rests\n",
        "\n",
        "def parse_args():\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "                        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument('--data_dir', type=str, default='data/midi2',\n",
        "                        help='data directory containing .mid files to use for' \\\n",
        "                             'training')\n",
        "    parser.add_argument('--experiment_dir', type=str,\n",
        "                        default='experiments/default',\n",
        "                        help='directory to store checkpointed models and tensorboard logs.' \\\n",
        "                             'if omitted, will create a new numbered folder in experiments/.')\n",
        "    parser.add_argument('--rnn_size', type=int, default=64,\n",
        "                        help='size of RNN hidden state')\n",
        "    parser.add_argument('--num_layers', type=int, default=1,\n",
        "                        help='number of layers in the RNN')\n",
        "    parser.add_argument('--learning_rate', type=float, default=None,\n",
        "                        help='learning rate. If not specified, the recommended learning '\\\n",
        "                        'rate for the chosen optimizer is used.')\n",
        "    parser.add_argument('--window_size', type=int, default=20,\n",
        "                        help='Window size for RNN input per step.')\n",
        "    parser.add_argument('--batch_size', type=int, default=32,\n",
        "                        help='minibatch size')\n",
        "    parser.add_argument('--num_epochs', type=int, default=10,\n",
        "                        help='number of epochs before stopping training.')\n",
        "    parser.add_argument('--dropout', type=float, default=0.2,\n",
        "                        help='percentage of weights that are turned off every training '\\\n",
        "                        'set step. This is a popular regularization that can help with '\\\n",
        "                        'overfitting. Recommended values are 0.2-0.5')\n",
        "    parser.add_argument('--optimizer', \n",
        "                        choices=['sgd', 'rmsprop', 'adagrad', 'adadelta', \n",
        "                                 'adam', 'adamax', 'nadam'], default='adam',\n",
        "                        help='The optimization algorithm to use. '\\\n",
        "                        'See https://keras.io/optimizers for a full list of optimizers.')\n",
        "    parser.add_argument('--grad_clip', type=float, default=5.0,\n",
        "                        help='clip gradients at this value.')\n",
        "    parser.add_argument('--message', '-m', type=str,\n",
        "                        help='a note to self about the experiment saved to message.txt '\\\n",
        "                        'in --experiment_dir.')\n",
        "    parser.add_argument('--n_jobs', '-j', type=int, default=1, \n",
        "                        help='Number of CPUs to use when loading and parsing midi files.')\n",
        "    parser.add_argument('--max_files_in_ram', default=25, type=int,\n",
        "                        help='The maximum number of midi files to load into RAM at once.'\\\n",
        "                        ' A higher value trains faster but uses more RAM. A lower value '\\\n",
        "                        'uses less RAM but takes significantly longer to train.')\n",
        "    return parser.parse_args()\n",
        "\n",
        "# create or load a saved model\n",
        "# returns the model and the epoch number (>1 if loaded from checkpoint)\n",
        "def get_model(experiment_dir=None):\n",
        "    \n",
        "    epoch = 0\n",
        "    num_layers = 1\n",
        "    rnn_size = 64\n",
        "    window_size = 20\n",
        "    dropout = 0.2\n",
        "    grad_clip = 5\n",
        "    learning_rate = None\n",
        "    optimizer = \"adam\"\n",
        "    if not experiment_dir:\n",
        "        model = Sequential()\n",
        "        for layer_index in range(num_layers):\n",
        "            kwargs = dict() \n",
        "            kwargs['units'] = rnn_size\n",
        "            # if this is the first layer\n",
        "            print(\"inside get_model\")\n",
        "            if layer_index == 0:\n",
        "                kwargs['input_shape'] = (window_size, OUTPUT_SIZE)\n",
        "                if num_layers == 1:\n",
        "                    kwargs['return_sequences'] = False\n",
        "                else:\n",
        "                    kwargs['return_sequences'] = True\n",
        "                model.add(LSTM(**kwargs))\n",
        "            else:\n",
        "                # if this is a middle layer\n",
        "                if not layer_index == num_layers - 1:\n",
        "                    kwargs['return_sequences'] = True\n",
        "                    model.add(LSTM(**kwargs))\n",
        "                else: # this is the last layer\n",
        "                    kwargs['return_sequences'] = False\n",
        "                    model.add(LSTM(**kwargs))\n",
        "            model.add(Dropout(dropout))\n",
        "        model.add(Dense(OUTPUT_SIZE))\n",
        "        model.add(Activation('softmax'))\n",
        "    else:\n",
        "        model, epoch = load_model_from_checkpoint(experiment_dir)\n",
        "\n",
        "    # these cli args aren't specified if get_model() is being\n",
        "    # being called from sample.py\n",
        "    args2 = [\"grad_clip\",\"optimizer\"]\n",
        "    if 'grad_clip' in args2 and 'optimizer' in args2:\n",
        "        kwargs = { 'clipvalue': grad_clip }\n",
        "\n",
        "        if learning_rate:\n",
        "            kwargs['lr'] = learning_rate\n",
        "\n",
        "        # select the optimizers\n",
        "        if optimizer == 'sgd':\n",
        "            optimizer = SGD(**kwargs)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            optimizer = RMSprop(**kwargs)\n",
        "        elif optimizer == 'adagrad':\n",
        "            optimizer = Adagrad(**kwargs)\n",
        "        elif optimizer == 'adadelta':\n",
        "            optimizer = Adadelta(**kwargs)\n",
        "        elif optimizer == 'adam':\n",
        "            optimizer = Adam(**kwargs)\n",
        "        elif optimizer == 'adamax':\n",
        "            optimizer = Adamax(**kwargs)\n",
        "        elif optimizer == 'nadam':\n",
        "            optimizer = Nadam(**kwargs)\n",
        "        else:\n",
        "            log(\n",
        "                'Error: {} is not a supported optimizer. Exiting.'.format(optimizer),\n",
        "                True)\n",
        "            exit(1)\n",
        "    else: # so instead lets use a default (no training occurs anyway)\n",
        "        optimizer = Adam()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    return model, epoch\n",
        "\n",
        "def get_callbacks(experiment_dir, checkpoint_monitor='val_acc'):\n",
        "    \n",
        "    callbacks = []\n",
        "    \n",
        "    # save model checkpoints\n",
        "    filepath = os.path.join(experiment_dir, \n",
        "                            'checkpoints', \n",
        "                            'checkpoint-epoch_{epoch:03d}-val_acc_{val_accuracy:.3f}.hdf5')\n",
        "    print(filepath)\n",
        "\n",
        "    callbacks.append(ModelCheckpoint(filepath = filepath, \n",
        "                                     monitor=checkpoint_monitor, \n",
        "                                     verbose=1, \n",
        "                                     save_best_only=False, \n",
        "                                     mode='max'))\n",
        "\n",
        "    callbacks.append(ReduceLROnPlateau(monitor='val_loss', \n",
        "                                       factor=0.5, \n",
        "                                       patience=3, \n",
        "                                       verbose=1, \n",
        "                                       mode='auto', \n",
        "                                       epsilon=0.0001, \n",
        "                                       cooldown=0, \n",
        "                                       min_lr=0))\n",
        "\n",
        "    callbacks.append(TensorBoard(log_dir=os.path.join(experiment_dir, 'tensorboard-logs'), \n",
        "                                histogram_freq=0, \n",
        "                                write_graph=True, \n",
        "                                write_images=False))\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "def main():\n",
        "\n",
        "    # args = parse_args()\n",
        "    # args.verbose = True\n",
        "    \n",
        "    data_dir = \"data/midi2\"\n",
        "    verbose = True\n",
        "\n",
        "\n",
        "    try:\n",
        "        # get paths to midi files in --data_dir\n",
        "        midi_files = [os.path.join(data_dir, path) \\\n",
        "                      for path in os.listdir(data_dir) \\\n",
        "                      if '.mid' in path or '.midi' in path]\n",
        "    except OSError as e:\n",
        "        log('Error: Invalid --data_dir, {} directory does not exist. Exiting.', verbose)\n",
        "        exit(1)\n",
        "    print(midi_files)\n",
        "    log(\n",
        "        'Found {} midi files in {}'.format(len(midi_files), \"data/midi\"),\n",
        "        True\n",
        "    )\n",
        "\n",
        "    if len(midi_files) < 1:\n",
        "        log(\n",
        "            'Error: no midi files found in {}. Exiting.'.format(\"data/midi\"),\n",
        "            True\n",
        "        )\n",
        "        exit(1)\n",
        "\n",
        "    # create the experiment directory and return its name\n",
        "    experiment_dir = create_experiment_dir(\"experiments/default\", True)\n",
        "\n",
        "    # write --message to experiment_dir\n",
        "    # if args.message:\n",
        "    #     with open(os.path.join(experiment_dir, 'message.txt'), 'w') as f:\n",
        "    #         f.write(args.message)\n",
        "    #         log('Wrote {} bytes to {}'.format(len(args.message), \n",
        "    #             os.path.join(experiment_dir, 'message.txt')), args.verbose)\n",
        "\n",
        "    val_split = 0.2 # use 20 percent for validation\n",
        "    val_split_index = int(float(len(midi_files)) * val_split)\n",
        "\n",
        "    window_size = 20\n",
        "    batch_size = 32\n",
        "    n_jobs = 1\n",
        "    max_files_in_ram = 25\n",
        "    num_epochs = 1\n",
        "    verbose = True\n",
        "    # use generators to lazy load train/validation data, ensuring that the\n",
        "    # user doesn't have to load all midi files into RAM at once\n",
        "    train_generator = get_data_generator(midi_files[0:val_split_index], \n",
        "                                               window_size=window_size,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_threads=n_jobs,\n",
        "                                               max_files_in_ram=max_files_in_ram)\n",
        "\n",
        "    val_generator = get_data_generator(midi_files[val_split_index:], \n",
        "                                             window_size=window_size,\n",
        "                                             batch_size=batch_size,\n",
        "                                             num_threads=n_jobs,\n",
        "                                             max_files_in_ram=max_files_in_ram)\n",
        "\n",
        "    model, epoch = get_model()\n",
        "    if verbose:\n",
        "        print(model.summary())\n",
        "\n",
        "    save_model(model, experiment_dir)\n",
        "    log('Saved model to {}'.format(os.path.join(experiment_dir, 'model.json')),\n",
        "              verbose)\n",
        "\n",
        "    callbacks = get_callbacks(experiment_dir)\n",
        "    \n",
        "    print('fitting model...')\n",
        "    # this is a somewhat magic number which is the average number of length-20 windows\n",
        "    # calculated from ~5K MIDI files from the Lakh MIDI Dataset.\n",
        "    magic_number = 827\n",
        "    start_time = time.time()\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=len(midi_files) * magic_number / batch_size, \n",
        "                        epochs=num_epochs,\n",
        "                        validation_data=val_generator, \n",
        "                        validation_steps=len(midi_files) * 0.2 * magic_number / batch_size,\n",
        "                        verbose=1, \n",
        "                        callbacks=callbacks,\n",
        "                        initial_epoch=epoch)\n",
        "    log('Finished in {:.2f} seconds'.format(time.time() - start_time), verbose)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "# tensorflow.debugging.set_log_device_placement(True)\n",
        "main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/midi2/FF1prelu.mid', 'data/midi2/FF1cave.mid', 'data/midi2/FF1town.mid', 'data/midi2/FF1ship.mid', 'data/midi2/FF1epilo.mid', 'data/midi2/FF1chaos.mid', 'data/midi2/FF1menu.mid', 'data/midi2/FF1shop.mid', 'data/midi2/FF1slain.mid', 'data/midi2/FF1under.mid', 'data/midi2/FF1castl.mid', 'data/midi2/FF1matou.mid', 'data/midi2/FF1world.mid', 'data/midi2/FF1airsh.mid', 'data/midi2/FF1battl.mid', 'data/midi2/FF1float.mid', 'data/midi2/FF1prolo.mid']\n",
            "[*] Found 17 midi files in data/midi\n",
            "[*] Created experiment directory experiments/19\n",
            "[*] Created checkpoint directory experiments/19/checkpoints\n",
            "[*] Created log directory experiments/19/tensorboard-logs\n",
            "inside get_model\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 64)                49664     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 129)               8385      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 129)               0         \n",
            "=================================================================\n",
            "Total params: 58,049\n",
            "Trainable params: 58,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "[*] Saved model to experiments/19/model.json\n",
            "experiments/19/checkpoints/checkpoint-epoch_{epoch:03d}-val_acc_{val_accuracy:.3f}.hdf5\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "fitting model...\n",
            "437/439 [============================>.] - ETA: 0s - loss: 3.3185 - accuracy: 0.2835\n",
            "Epoch 00001: saving model to experiments/19/checkpoints/checkpoint-epoch_001-val_acc_0.246.hdf5\n",
            "440/439 [==============================] - 14s 32ms/step - loss: 3.3136 - accuracy: 0.2833 - val_loss: 3.5225 - val_accuracy: 0.2464\n",
            "[*] Finished in 14.18 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJt7w4a0nJ2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c10f6cc2-465c-4fc5-c142-0c89ff1848ad"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "import argparse, os, pdb\n",
        "import pretty_midi\n",
        "# import train\n",
        "# import utils\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "                       formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument('--experiment_dir', type=str,\n",
        "                        default='experiments/default',\n",
        "                        help='directory to load saved model from. ' \\\n",
        "                             'If omitted, it will use the most recent directory from ' \\\n",
        "                             'experiments/.')\n",
        "    parser.add_argument('--save_dir', type=str,\n",
        "    \t\t\t\t\thelp='directory to save generated files to. Directory will be ' \\\n",
        "    \t\t\t\t\t'created if it doesn\\'t already exist. If not specified, ' \\\n",
        "    \t\t\t\t\t'files will be saved to generated/ inside --experiment_dir.')\n",
        "    parser.add_argument('--midi_instrument', default='Acoustic Grand Piano',\n",
        "                        help='MIDI instrument name (or number) to use for the ' \\\n",
        "                        'generated files. See https://www.midi.org/specifications/item/'\\\n",
        "                        'gm-level-1-sound-set for a full list of instrument names.')\n",
        "    parser.add_argument('--num_files', type=int, default=10,\n",
        "                        help='number of midi files to sample.')\n",
        "    parser.add_argument('--file_length', type=int, default=1000,\n",
        "    \t\t\t\t\thelp='Length of each file, measured in 16th notes.')\n",
        "    parser.add_argument('--prime_file', type=str,\n",
        "                        help='prime generated files from midi file. If not specified ' \\\n",
        "                        'random windows from the validation dataset will be used for ' \\\n",
        "                        'for seeding.')\n",
        "    parser.add_argument('--data_dir', type=str, default='data/midi',\n",
        "                        help='data directory containing .mid files to use for' \\\n",
        "                             'seeding/priming. Required if --prime_file is not specified')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def get_experiment_dir(experiment_dir):\n",
        "\t\n",
        "\tif experiment_dir == 'experiments/default':\n",
        "\t\tdirs_ = [os.path.join('experiments', d) for d in os.listdir('experiments') \\\n",
        "\t\t         if os.path.isdir(os.path.join('experiments', d))]\n",
        "\t\texperiment_dir = max(dirs_, key=os.path.getmtime)\n",
        "\n",
        "\tif not os.path.exists(os.path.join(experiment_dir, 'model.json')):\n",
        "\t\tlog('Error: {} does not exist. ' \\\n",
        "\t\t\t      'Are you sure that {} is a valid experiment?' \\\n",
        "\t\t\t      'Exiting.'.format(os.path.join(args.experiment_dir), 'model.json',\n",
        "\t\t\t                        experiment_dir), True)\n",
        "\t\texit(1)\n",
        "\n",
        "\treturn experiment_dir\n",
        "\n",
        "def main2():\n",
        "\n",
        "    verbose = True\n",
        "    data_dir = \"data/midi2\"\n",
        "    experiment_dir = \"experiments/default\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    midi_files = [ os.path.join(data_dir, f) for f in os.listdir(data_dir) \\\n",
        "                 if '.mid' in f or '.midi' in f ]\n",
        "\n",
        "    experiment_dir = get_experiment_dir(experiment_dir)\n",
        "    log('Using {} as --experiment_dir'.format(experiment_dir), verbose)\n",
        "\n",
        "    save_dir = os.path.join(experiment_dir, 'generated')\n",
        "\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "        log('Created directory {}'.format(save_dir), verbose)\n",
        "    \n",
        "    model, epoch = get_model(experiment_dir=experiment_dir)\n",
        "    print(\"test\")\n",
        "    log('Model loaded from {}'.format(os.path.join(experiment_dir, 'model.json')), \n",
        "              verbose)\n",
        "\n",
        "    window_size = model.layers[0].get_input_shape_at(0)[1]\n",
        "    seed_generator = get_data_generator(midi_files, \n",
        "                                              window_size=window_size,\n",
        "                                              batch_size=32,\n",
        "                                              num_threads=1,\n",
        "                                              max_files_in_ram=10)\n",
        "\n",
        "    midi_instrument = \"Acoustic Bass\"\n",
        "    file_length = 1000\n",
        "    num_files = 2\n",
        "\n",
        "    # validate midi instrument name\n",
        "    try:\n",
        "    \t# try and parse the instrument name as an int\n",
        "    \tinstrument_num = int(midi_instrument)\n",
        "    \tif not (instrument_num >= 0 and instrument_num <=127):\n",
        "          # print(\"error\")\n",
        "    \t\tlog('Error: {} is not a supported instrument. Number values must be ' \\\n",
        "    \t\t\t      'be 0-127. Exiting'.format(midi_instrument), True)\n",
        "    \t\texit(1)\n",
        "    \tmidi_instrument = pretty_midi.program_to_instrument_name(instrument_num)\n",
        "    except ValueError as err:\n",
        "    \t# if the instrument name is a string\n",
        "    \ttry:\n",
        "    \t\t# validate that it can be converted to a program number\n",
        "    \t\t_ = pretty_midi.instrument_name_to_program(midi_instrument)\n",
        "    \texcept ValueError as er:\n",
        "        # print(\"error\")\n",
        "    \t\tlog('Error: {} is not a valid General MIDI instrument. Exiting.'\\\n",
        "    \t\t\t      .format(midi_instrument), True)\n",
        "    \t\texit(1)\n",
        "\n",
        "\n",
        "    # log('Loading seed files...', verbose)\n",
        "    X, y = next(seed_generator)\n",
        "    generated = generate(model, X, window_size, \n",
        "    \t                       file_length, num_files, midi_instrument)\n",
        "    for i, midi in enumerate(generated):\n",
        "        file = os.path.join(save_dir, '{}.mid'.format(i + 1))\n",
        "        midi.write(file.format(i + 1))\n",
        "        log('wrote midi file to {}'.format(file), True)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "main2()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "[*] Using experiments/19 as --experiment_dir\n",
            "[*] Created directory experiments/19/generated\n",
            "experiments/19/checkpoints/checkpoint-epoch_001-val_acc_0.246.hdf5\n",
            "test\n",
            "[*] Model loaded from experiments/19/model.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFiva_7sBiZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97418488-a205-413a-89b6-f317152fc46b"
      },
      "source": [
        "%reset"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS7AQWc5nf9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}