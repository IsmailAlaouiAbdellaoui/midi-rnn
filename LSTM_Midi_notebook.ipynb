{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Midi-notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixWUDEPccHrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "!pip install grpcio==1.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYMfKFd4cl9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cabe5ef-2c6d-41d2-99a9-10dfe5754fbf"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: \",tf.__version__)\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "\n",
        "string = ('data', '/midi')\n",
        "s = ''\n",
        "dir = s.join(string)\n",
        "\n",
        "#creating data folder\n",
        "if not os.path.isdir(dir):\n",
        "  os.makedirs(dir)\n",
        "  print('Created directory {}'.format(dir))\n",
        "\n",
        "#creating experiments folder\n",
        "if not os.path.isdir(\"experiments\"):\n",
        "  os.makedirs(\"experiments\")\n",
        "  print('Created directory experiments')\n",
        "\n",
        "\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.0.0\n",
            "data  experiments  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2jENXOkxmpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9NBy72gujuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run Utility functions (double click to open) { form-width: \"15%\", display-mode: \"form\" }\n",
        "\n",
        "import os, glob, random\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from multiprocessing import Pool as ThreadPool\n",
        "\n",
        "def log(message, verbose):\n",
        "\tif verbose:\n",
        "\t\tprint('[*] {}'.format(message))\n",
        "\n",
        "def parse_midi(path):\n",
        "    midi = None\n",
        "    try:\n",
        "        midi = pretty_midi.PrettyMIDI(path)\n",
        "        midi.remove_invalid_notes()\n",
        "    except Exception as e:\n",
        "        raise Exception((\"%s\\nerror readying midi file %s\" % (e, path)))\n",
        "    return midi\n",
        "\n",
        "def get_percent_monophonic(pm_instrument_roll):\n",
        "    mask = pm_instrument_roll.T > 0\n",
        "    notes = np.sum(mask, axis=1)\n",
        "    n = np.count_nonzero(notes)\n",
        "    single = np.count_nonzero(notes == 1)\n",
        "    if single > 0:\n",
        "        return float(single) / float(n)\n",
        "    elif single == 0 and n > 0:\n",
        "        return 0.0\n",
        "    else: # no notes of any kind\n",
        "        return 0.0\n",
        "    \n",
        "def filter_monophonic(pm_instruments, percent_monophonic=0.99):\n",
        "    return [i for i in pm_instruments if \\\n",
        "            get_percent_monophonic(i.get_piano_roll()) >= percent_monophonic]\n",
        "\n",
        "\n",
        "# if the experiment dir doesn't exist create it and its subfolders\n",
        "def create_experiment_dir(experiment_dir, verbose=False):\n",
        "    \n",
        "    # if the experiment directory was specified and already exists\n",
        "    if experiment_dir != 'experiments/default' and \\\n",
        "       os.path.exists(experiment_dir):\n",
        "    \t# raise an error\n",
        "    \traise Exception('Error: Invalid --experiemnt_dir, {} already exists' \\\n",
        "    \t\t            .format(experiment_dir))\n",
        "\n",
        "    # if the experiment directory was not specified, create a new numeric folder\n",
        "    if experiment_dir == 'experiments/default':\n",
        "    \t\n",
        "    \texperiments = os.listdir('experiments')\n",
        "    \texperiments = [dir_ for dir_ in experiments \\\n",
        "    \t               if os.path.isdir(os.path.join('experiments', dir_))]\n",
        "    \t\n",
        "    \tmost_recent_exp = 0\n",
        "    \tfor dir_ in experiments:\n",
        "    \t\ttry:\n",
        "    \t\t\tmost_recent_exp = max(int(dir_), most_recent_exp)\n",
        "    \t\texcept ValueError as e:\n",
        "    \t\t\t# ignrore non-numeric folders in experiments/\n",
        "    \t\t\tpass\n",
        "\n",
        "    \texperiment_dir = os.path.join('experiments', \n",
        "    \t\t                          str(most_recent_exp + 1).rjust(2, '0'))\n",
        "\n",
        "    os.mkdir(experiment_dir)\n",
        "    log('Created experiment directory {}'.format(experiment_dir), verbose)\n",
        "    os.mkdir(os.path.join(experiment_dir, 'checkpoints'))\n",
        "    log('Created checkpoint directory {}'.format(os.path.join(experiment_dir, 'checkpoints')),\n",
        "    \tverbose)\n",
        "    os.mkdir(os.path.join(experiment_dir, 'tensorboard-logs'))\n",
        "    log('Created log directory {}'.format(os.path.join(experiment_dir, 'tensorboard-logs')), \n",
        "    \tverbose)\n",
        "\n",
        "    return experiment_dir\n",
        "\n",
        "# load data with a lazzy loader\n",
        "def get_data_generator(midi_paths, \n",
        "                       window_size=20, \n",
        "                       batch_size=32,\n",
        "                       num_threads=8,\n",
        "                       max_files_in_ram=170):\n",
        "\n",
        "    if num_threads > 1:\n",
        "    \t# load midi data\n",
        "    \tpool = ThreadPool(num_threads)\n",
        "\n",
        "    load_index = 0\n",
        "\n",
        "    while True:\n",
        "        load_files = midi_paths[load_index:load_index + max_files_in_ram]\n",
        "        # print('length of load files: {}'.format(len(load_files)))\n",
        "        load_index = (load_index + max_files_in_ram) % len(midi_paths)\n",
        "\n",
        "        # print('loading large batch: {}'.format(max_files_in_ram))\n",
        "        # print('Parsing midi files...')\n",
        "        # start_time = time.time()\n",
        "        if num_threads > 1:\n",
        "       \t\tparsed = pool.map(parse_midi, load_files)\n",
        "       \telse:\n",
        "       \t\tparsed = map(parse_midi, load_files)\n",
        "        # print('Finished in {:.2f} seconds'.format(time.time() - start_time))\n",
        "        # print('parsed, now extracting data')\n",
        "        data = _windows_from_monophonic_instruments(parsed, window_size)\n",
        "        batch_index = 0\n",
        "        while batch_index + batch_size < len(data[0]):\n",
        "            # print('getting data...')\n",
        "            # print('yielding small batch: {}'.format(batch_size))\n",
        "            \n",
        "            res = (data[0][batch_index: batch_index + batch_size], \n",
        "                   data[1][batch_index: batch_index + batch_size])\n",
        "            yield res\n",
        "            batch_index = batch_index + batch_size\n",
        "        \n",
        "        # probably unneeded but why not\n",
        "        del parsed # free the mem\n",
        "        del data # free the mem\n",
        "\n",
        "def save_model(model, model_dir):\n",
        "    with open(os.path.join(model_dir, 'model.json'), 'w') as f:\n",
        "        f.write(model.to_json())\n",
        "\n",
        "def load_model_from_checkpoint(model_dir):\n",
        "\n",
        "    '''Loads the best performing model from checkpoint_dir'''\n",
        "    with open(os.path.join(model_dir, 'model.json'), 'r') as f:\n",
        "        model = model_from_json(f.read())\n",
        "\n",
        "    epoch = 0\n",
        "    newest_checkpoint = max(glob.iglob(model_dir + \n",
        "    \t                    '/checkpoints/*.hdf5'), \n",
        "                            key=os.path.getctime)\n",
        "    print(newest_checkpoint)\n",
        "    if newest_checkpoint: \n",
        "      #  epoch = int(newest_checkpoint[-22:-19])\n",
        "       epoch = 1\n",
        "       model.load_weights(newest_checkpoint)\n",
        "\n",
        "    return model, epoch\n",
        "\n",
        "def generate(model, seeds, window_size, length, num_to_gen, instrument_name):\n",
        "    \n",
        "    # generate a pretty midi file from a model using a seed\n",
        "    def _gen(model, seed, window_size, length):\n",
        "        \n",
        "        generated = []\n",
        "        # ring buffer\n",
        "        buf = np.copy(seed).tolist()\n",
        "        while len(generated) < length:\n",
        "            arr = np.expand_dims(np.asarray(buf), 0)\n",
        "            pred = model.predict(arr)\n",
        "            \n",
        "            # argmax sampling (NOT RECOMMENDED), or...\n",
        "            # index = np.argmax(pred)\n",
        "            \n",
        "            # prob distrobuition sampling\n",
        "            index = np.random.choice(range(0, seed.shape[1]), p=pred[0])\n",
        "            pred = np.zeros(seed.shape[1])\n",
        "\n",
        "            pred[index] = 1\n",
        "            generated.append(pred)\n",
        "            buf.pop(0)\n",
        "            buf.append(pred)\n",
        "\n",
        "        return generated\n",
        "\n",
        "    midis = []\n",
        "    for i in range(0, num_to_gen):\n",
        "        seed = seeds[random.randint(0, len(seeds) - 1)]\n",
        "        gen = _gen(model, seed, window_size, length)\n",
        "        midis.append(_network_output_to_midi(gen, instrument_name))\n",
        "    return midis\n",
        "\n",
        "# create a pretty midi file with a single instrument using the one-hot encoding\n",
        "# output of keras model.predict.\n",
        "def _network_output_to_midi(windows, \n",
        "                           instrument_name='Acoustic Grand Piano', \n",
        "                           allow_represses=False):\n",
        "\n",
        "    # Create a PrettyMIDI object\n",
        "    midi = pretty_midi.PrettyMIDI()\n",
        "    # Create an Instrument instance for a cello instrument\n",
        "    instrument_program = pretty_midi.instrument_name_to_program(instrument_name)\n",
        "    instrument = pretty_midi.Instrument(program=instrument_program)\n",
        "    \n",
        "    cur_note = None # an invalid note to start with\n",
        "    cur_note_start = None\n",
        "    clock = 0\n",
        "\n",
        "    # Iterate over note names, which will be converted to note number later\n",
        "    for step in windows:\n",
        "\n",
        "        note_num = np.argmax(step) - 1\n",
        "        \n",
        "        # a note has changed\n",
        "        if allow_represses or note_num != cur_note:\n",
        "            \n",
        "            # if a note has been played before and it wasn't a rest\n",
        "            if cur_note is not None and cur_note >= 0:            \n",
        "                # add the last note, now that we have its end time\n",
        "                note = pretty_midi.Note(velocity=127, \n",
        "                                        pitch=int(cur_note), \n",
        "                                        start=cur_note_start, \n",
        "                                        end=clock)\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "            # update the current note\n",
        "            cur_note = note_num\n",
        "            cur_note_start = clock\n",
        "\n",
        "        # update the clock\n",
        "        clock = clock + 1.0 / 4\n",
        "\n",
        "    # Add the cello instrument to the PrettyMIDI object\n",
        "    midi.instruments.append(instrument)\n",
        "    return midi\n",
        "\n",
        "# returns X, y data windows from all monophonic instrument\n",
        "# tracks in a pretty midi file\n",
        "def _windows_from_monophonic_instruments(midi, window_size):\n",
        "    X, y = [], []\n",
        "    for m in midi:\n",
        "        if m is not None:\n",
        "            melody_instruments = filter_monophonic(m.instruments, 1.0)\n",
        "            for instrument in melody_instruments:\n",
        "                if len(instrument.notes) > window_size:\n",
        "                    windows = _encode_sliding_windows(instrument, window_size)\n",
        "                    for w in windows:\n",
        "                        X.append(w[0])\n",
        "                        y.append(w[1])\n",
        "    return (np.asarray(X), np.asarray(y))\n",
        "\n",
        "# one-hot encode a sliding window of notes from a pretty midi instrument.\n",
        "# This approach uses the piano roll method, where each step in the sliding\n",
        "# window represents a constant unit of time (fs=4, or 1 sec / 4 = 250ms).\n",
        "# This allows us to encode rests.\n",
        "# expects pm_instrument to be monophonic.\n",
        "def _encode_sliding_windows(pm_instrument, window_size):\n",
        "    \n",
        "    roll = np.copy(pm_instrument.get_piano_roll(fs=4).T)\n",
        "\n",
        "    # trim beginning silence\n",
        "    summed = np.sum(roll, axis=1)\n",
        "    mask = (summed > 0).astype(float)\n",
        "    roll = roll[np.argmax(mask):]\n",
        "    \n",
        "    # transform note velocities into 1s\n",
        "    roll = (roll > 0).astype(float)\n",
        "    \n",
        "    # calculate the percentage of the events that are rests\n",
        "    # s = np.sum(roll, axis=1)\n",
        "    # num_silence = len(np.where(s == 0)[0])\n",
        "    # print('{}/{} {:.2f} events are rests'.format(num_silence, len(roll), float(num_silence)/float(len(roll))))\n",
        "\n",
        "    # append a feature: 1 to rests and 0 to notes\n",
        "    rests = np.sum(roll, axis=1)\n",
        "    rests = (rests != 1).astype(float)\n",
        "    roll = np.insert(roll, 0, rests, axis=1)\n",
        "    \n",
        "    windows = []\n",
        "    for i in range(0, roll.shape[0] - window_size - 1):\n",
        "        windows.append((roll[i:i + window_size], roll[i + window_size + 1]))\n",
        "    return windows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjIEU850vBGA",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRPZ1YoAvFbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, argparse, time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
        "\n",
        "OUTPUT_SIZE = 129 # 0-127 notes + 1 for rests\n",
        "\n",
        "# create or load a saved model\n",
        "# returns the model and the epoch number (>1 if loaded from checkpoint)\n",
        "\n",
        "def get_model(experiment_dir=None):\n",
        "    \n",
        "    epoch = 0\n",
        "    num_layers = 1\n",
        "    rnn_size = 64\n",
        "    window_size = 20\n",
        "    dropout = 0.2\n",
        "    grad_clip = 5\n",
        "    learning_rate = None\n",
        "    optimizer = \"adam\"\n",
        "    if not experiment_dir:\n",
        "        model = Sequential()\n",
        "        for layer_index in range(num_layers):\n",
        "            kwargs = dict() \n",
        "            kwargs['units'] = rnn_size\n",
        "            # if this is the first layer\n",
        "            if layer_index == 0:\n",
        "                kwargs['input_shape'] = (window_size, OUTPUT_SIZE)\n",
        "                if num_layers == 1:\n",
        "                    kwargs['return_sequences'] = False\n",
        "                else:\n",
        "                    kwargs['return_sequences'] = True\n",
        "                model.add(LSTM(**kwargs))\n",
        "            else:\n",
        "                # if this is a middle layer\n",
        "                if not layer_index == num_layers - 1:\n",
        "                    kwargs['return_sequences'] = True\n",
        "                    model.add(LSTM(**kwargs))\n",
        "                else: # this is the last layer\n",
        "                    kwargs['return_sequences'] = False\n",
        "                    model.add(LSTM(**kwargs))\n",
        "            model.add(Dropout(dropout))\n",
        "        model.add(Dense(OUTPUT_SIZE))\n",
        "        model.add(Activation('softmax'))\n",
        "    else:\n",
        "        model, epoch = load_model_from_checkpoint(experiment_dir)\n",
        "\n",
        "    # these cli args aren't specified if get_model() is being\n",
        "    # being called from sample.py\n",
        "    args2 = [\"grad_clip\",\"optimizer\"]#dumb workaround for existing code\n",
        "    if 'grad_clip' in args2 and 'optimizer' in args2:\n",
        "        kwargs = { 'clipvalue': grad_clip }\n",
        "\n",
        "        if learning_rate:\n",
        "            kwargs['lr'] = learning_rate\n",
        "\n",
        "        # select the optimizers\n",
        "        if optimizer == 'sgd':\n",
        "            optimizer = SGD(**kwargs)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            optimizer = RMSprop(**kwargs)\n",
        "        elif optimizer == 'adagrad':\n",
        "            optimizer = Adagrad(**kwargs)\n",
        "        elif optimizer == 'adadelta':\n",
        "            optimizer = Adadelta(**kwargs)\n",
        "        elif optimizer == 'adam':\n",
        "            optimizer = Adam(**kwargs)\n",
        "        elif optimizer == 'adamax':\n",
        "            optimizer = Adamax(**kwargs)\n",
        "        elif optimizer == 'nadam':\n",
        "            optimizer = Nadam(**kwargs)\n",
        "        else:\n",
        "            log(\n",
        "                'Error: {} is not a supported optimizer. Exiting.'.format(optimizer),\n",
        "                True)\n",
        "            exit(1)\n",
        "    else: # so instead lets use a default (no training occurs anyway)\n",
        "        optimizer = Adam()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    return model, epoch\n",
        "\n",
        "\n",
        "def get_callbacks(experiment_dir, checkpoint_monitor='val_acc'):\n",
        "    \n",
        "    callbacks = []\n",
        "    \n",
        "    # save model checkpoints\n",
        "    filepath = os.path.join(experiment_dir, \n",
        "                            'checkpoints', \n",
        "                            'checkpoint-epoch_{epoch:03d}-val_acc_{val_accuracy:.3f}.hdf5')\n",
        "    print(filepath)\n",
        "\n",
        "    callbacks.append(ModelCheckpoint(filepath = filepath, \n",
        "                                     monitor=checkpoint_monitor, \n",
        "                                     verbose=1, \n",
        "                                     save_best_only=False, \n",
        "                                     mode='max'))\n",
        "\n",
        "    callbacks.append(ReduceLROnPlateau(monitor='val_loss', \n",
        "                                       factor=0.5, \n",
        "                                       patience=3, \n",
        "                                       verbose=1, \n",
        "                                       mode='auto', \n",
        "                                       epsilon=0.0001, \n",
        "                                       cooldown=0, \n",
        "                                       min_lr=0))\n",
        "\n",
        "    callbacks.append(TensorBoard(log_dir=os.path.join(experiment_dir, 'tensorboard-logs'), \n",
        "                                histogram_freq=0, \n",
        "                                write_graph=True, \n",
        "                                write_images=False))\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "def main():\n",
        "    \n",
        "    data_dir = \"data/midi\"\n",
        "    verbose = True\n",
        "\n",
        "\n",
        "    try:\n",
        "        # get paths to midi files in --data_dir\n",
        "        midi_files = [os.path.join(data_dir, path) \\\n",
        "                      for path in os.listdir(data_dir) \\\n",
        "                      if '.mid' in path or '.midi' in path]\n",
        "    except OSError as e:\n",
        "        log('Error: Invalid --data_dir, {} directory does not exist. Exiting.', verbose)\n",
        "        exit(1)\n",
        "    print(midi_files)\n",
        "    log(\n",
        "        'Found {} midi files in {}'.format(len(midi_files), \"data/midi\"),\n",
        "        True\n",
        "    )\n",
        "\n",
        "    if len(midi_files) < 1:\n",
        "        log(\n",
        "            'Error: no midi files found in {}. Exiting.'.format(\"data/midi\"),\n",
        "            True\n",
        "        )\n",
        "        exit(1)\n",
        "\n",
        "    # create the experiment directory and return its name\n",
        "    experiment_dir = create_experiment_dir(\"experiments/default\", True)\n",
        "\n",
        "    # write --message to experiment_dir\n",
        "    # if args.message:\n",
        "    #     with open(os.path.join(experiment_dir, 'message.txt'), 'w') as f:\n",
        "    #         f.write(args.message)\n",
        "    #         log('Wrote {} bytes to {}'.format(len(args.message), \n",
        "    #             os.path.join(experiment_dir, 'message.txt')), args.verbose)\n",
        "\n",
        "    val_split = 0.2 # use 20 percent for validation\n",
        "    val_split_index = int(float(len(midi_files)) * val_split)\n",
        "\n",
        "    window_size = 20\n",
        "    batch_size = 32\n",
        "    n_jobs = 1\n",
        "    max_files_in_ram = 25\n",
        "    num_epochs = 50\n",
        "    verbose = True\n",
        "    # use generators to lazy load train/validation data, ensuring that the\n",
        "    # user doesn't have to load all midi files into RAM at once\n",
        "    train_generator = get_data_generator(midi_files[0:val_split_index], \n",
        "                                               window_size=window_size,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_threads=n_jobs,\n",
        "                                               max_files_in_ram=max_files_in_ram)\n",
        "\n",
        "    val_generator = get_data_generator(midi_files[val_split_index:], \n",
        "                                             window_size=window_size,\n",
        "                                             batch_size=batch_size,\n",
        "                                             num_threads=n_jobs,\n",
        "                                             max_files_in_ram=max_files_in_ram)\n",
        "\n",
        "    model, epoch = get_model()\n",
        "    if verbose:\n",
        "        print(model.summary())\n",
        "\n",
        "    save_model(model, experiment_dir)\n",
        "    log('Saved model to {}'.format(os.path.join(experiment_dir, 'model.json')),\n",
        "              verbose)\n",
        "\n",
        "    callbacks = get_callbacks(experiment_dir)\n",
        "    \n",
        "    print('fitting model...')\n",
        "    # this is a somewhat magic number which is the average number of length-20 windows\n",
        "    # calculated from ~5K MIDI files from the Lakh MIDI Dataset.\n",
        "    magic_number = 827\n",
        "    start_time = time.time()\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=len(midi_files) * magic_number / batch_size, \n",
        "                        epochs=num_epochs,\n",
        "                        validation_data=val_generator, \n",
        "                        validation_steps=len(midi_files) * 0.2 * magic_number / batch_size,\n",
        "                        verbose=1, \n",
        "                        callbacks=callbacks,\n",
        "                        initial_epoch=epoch)\n",
        "    log('Finished in {:.2f} seconds'.format(time.time() - start_time), verbose)\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h006HFge1Chv",
        "colab_type": "text"
      },
      "source": [
        "# Generating new midi files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdssAyS1NJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse, os, pdb\n",
        "import pretty_midi\n",
        "\n",
        "\n",
        "def get_experiment_dir(experiment_dir):\n",
        "\t\n",
        "\tif experiment_dir == 'experiments/default':\n",
        "\t\tdirs_ = [os.path.join('experiments', d) for d in os.listdir('experiments') \\\n",
        "\t\t         if os.path.isdir(os.path.join('experiments', d))]\n",
        "\t\texperiment_dir = max(dirs_, key=os.path.getmtime)\n",
        "\n",
        "\tif not os.path.exists(os.path.join(experiment_dir, 'model.json')):\n",
        "\t\tlog('Error: {} does not exist. ' \\\n",
        "\t\t\t      'Are you sure that {} is a valid experiment?' \\\n",
        "\t\t\t      'Exiting.'.format(os.path.join(args.experiment_dir), 'model.json',\n",
        "\t\t\t                        experiment_dir), True)\n",
        "\t\texit(1)\n",
        "\n",
        "\treturn experiment_dir\n",
        "\n",
        "def main2(number_files, instrument, length_file):\n",
        "\n",
        "    verbose = True\n",
        "    data_dir = \"data/midi\"\n",
        "    experiment_dir = \"experiments/default\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    midi_files = [ os.path.join(data_dir, f) for f in os.listdir(data_dir) \\\n",
        "                 if '.mid' in f or '.midi' in f ]\n",
        "\n",
        "    experiment_dir = get_experiment_dir(experiment_dir)\n",
        "    log('Using {} as --experiment_dir'.format(experiment_dir), verbose)\n",
        "\n",
        "    save_dir = os.path.join(experiment_dir, 'generated')\n",
        "\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "        log('Created directory {}'.format(save_dir), verbose)\n",
        "    \n",
        "    model, epoch = get_model(experiment_dir=experiment_dir)\n",
        "    print(\"test\")\n",
        "    log('Model loaded from {}'.format(os.path.join(experiment_dir, 'model.json')), \n",
        "              verbose)\n",
        "\n",
        "    window_size = model.layers[0].get_input_shape_at(0)[1]\n",
        "    seed_generator = get_data_generator(midi_files, \n",
        "                                              window_size=window_size,\n",
        "                                              batch_size=32,\n",
        "                                              num_threads=1,\n",
        "                                              max_files_in_ram=10)\n",
        "\n",
        "    midi_instrument = instrument\n",
        "    file_length = length_file\n",
        "    num_files = number_files\n",
        "\n",
        "    # validate midi instrument name\n",
        "    try:\n",
        "    \t# try and parse the instrument name as an int\n",
        "    \tinstrument_num = int(midi_instrument)\n",
        "    \tif not (instrument_num >= 0 and instrument_num <=127):\n",
        "          # print(\"error\")\n",
        "    \t\tlog('Error: {} is not a supported instrument. Number values must be ' \\\n",
        "    \t\t\t      'be 0-127. Exiting'.format(midi_instrument), True)\n",
        "    \t\texit(1)\n",
        "    \tmidi_instrument = pretty_midi.program_to_instrument_name(instrument_num)\n",
        "    except ValueError as err:\n",
        "    \t# if the instrument name is a string\n",
        "    \ttry:\n",
        "    \t\t# validate that it can be converted to a program number\n",
        "    \t\t_ = pretty_midi.instrument_name_to_program(midi_instrument)\n",
        "    \texcept ValueError as er:\n",
        "        # print(\"error\")\n",
        "    \t\tlog('Error: {} is not a valid General MIDI instrument. Exiting.'\\\n",
        "    \t\t\t      .format(midi_instrument), True)\n",
        "    \t\texit(1)\n",
        "\n",
        "\n",
        "    # log('Loading seed files...', verbose)\n",
        "    X, y = next(seed_generator)\n",
        "    generated = generate(model, X, window_size, \n",
        "    \t                       file_length, num_files, midi_instrument)\n",
        "    for i, midi in enumerate(generated):\n",
        "        file = os.path.join(save_dir, '{}.mid'.format(i + 1))\n",
        "        midi.write(file.format(i + 1))\n",
        "        log('wrote midi file to {}'.format(file), True)\n",
        "\n",
        "number_files = 10\n",
        "instrument = \"Acoustic Bass\"\n",
        "length_file = 1000\n",
        "main2(number_files, instrument, length_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lpj2iTpewzG",
        "colab_type": "text"
      },
      "source": [
        "# Plotting graphs in tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnvxp_HjSkcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext tensorboard\n",
        "# %load_ext tensorboard\n",
        "%tensorboard --logdir experiments --port 6008"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}